{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entire code works perfectly fine!!!\n",
    "\n",
    "# At NLP Course L3-S18 (8:30), I did nltk.download('punkt') to download just 'punkt', \n",
    "# instead of what he shows using nltk.download() and that GUI thing - and it worked !\n",
    "\n",
    "# I increased the disk space on Ubuntu_ANN to 60 GB !!!\n",
    "# See Windows machine bookmarks -> 'Ubuntu_ANN_stuff' folder for steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code is for my NLP Udemy class, which can be found at:\n",
    "# https://deeplearningcourses.com/c/data-science-natural-language-processing-in-python\n",
    "# https://www.udemy.com/data-science-natural-language-processing-in-python\n",
    "# It is written in such a way that tells a story.\n",
    "# i.e. So you can follow a thought process of starting from a\n",
    "# simple idea, hitting an obstacle, overcoming it, etc.\n",
    "# i.e. It is not optimized for anything.\n",
    "\n",
    "# Author: http://lazyprogrammer.me\n",
    "# from __future__ import print_function, division\n",
    "# from future.utils import iteritems\n",
    "# from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()     # for stem words\n",
    "\n",
    "# from http://www.lextek.com/manuals/onix/stopwords1.html\n",
    "stopwords = set(w.rstrip() for w in open('stopwords.txt')) # this stopwords.txt file is there\n",
    "                                                           # in the current folder !\n",
    "# note: an alternative source of stopwords\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rve2/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/rve2/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# load the reviews\n",
    "# data courtesy of http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html\n",
    "\n",
    "# BeautifulSoup is for reading XML data - need to look at ATBSWP book!\n",
    "\n",
    "positive_reviews = BeautifulSoup(open('electronics/positive.review').read()) # returns what ?\n",
    "positive_reviews = positive_reviews.findAll('review_text')\n",
    "\n",
    "negative_reviews = BeautifulSoup(open('electronics/negative.review').read())\n",
    "negative_reviews = negative_reviews.findAll('review_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<review_text>\n",
       " I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\n",
       " \n",
       " I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
       " \n",
       " As always, Amazon had it to me in &lt;2 business days\n",
       " </review_text>, <review_text>\n",
       " I ordered 3 APC Back-UPS ES 500s on the recommendation of an employee of mine who used to work at APC. I've had them for about a month now without any problems. They've functioned properly through a few unexpected power interruptions. I'll gladly order more if the need arises.\n",
       " \n",
       " Pros:\n",
       "  - Large plug spacing, good for power adapters\n",
       "  - Simple design\n",
       "  - Long cord\n",
       " \n",
       " Cons:\n",
       "  - No line conditioning (usually an expensive option\n",
       " </review_text>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[:2]      \n",
    "\n",
    "# just looking at the first 2 positive_reviews !\n",
    "# so this is what the .findAll('review_text') returned !!!\n",
    "# note the <review_text> interspersed in one long string like Object \n",
    "# Think of positive_reviews as an Obj whose delimiters are <review_text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\\n\\nI feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\\n\\nAs always, Amazon had it to me in <2 business days\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews[0].text      # note the .text attribute of each review!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there are more positive reviews than negative reviews\n",
    "# so let's take a random sample so we have balanced classes\n",
    "# np.random.shuffle(positive_reviews)\n",
    "# positive_reviews = positive_reviews[:len(negative_reviews)]\n",
    "\n",
    "# we can also oversample the negative reviews\n",
    "diff = len(positive_reviews) - len(negative_reviews)\n",
    "idxs = np.random.choice(len(negative_reviews), size=diff)\n",
    "\n",
    "extra = [negative_reviews[i] for i in idxs]\n",
    "negative_reviews += extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff  # heck, just like I thought!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first let's just try to tokenize the text using nltk's tokenizer\n",
    "# let's take the first review for example:\n",
    "# t = positive_reviews[0]\n",
    "# nltk.tokenize.word_tokenize(t.text)\n",
    "#\n",
    "# notice how it doesn't downcase, so It != it\n",
    "# not only that, but do we really want to include the word \"it\" anyway?\n",
    "# you can imagine it wouldn't be any more common in a positive review than a negative review\n",
    "# so it might only add noise to our model.\n",
    "# so let's create a function that does all this pre-processing for us\n",
    "\n",
    "def my_tokenizer(s):    # s is going to be each review - see later\n",
    "    s = s.lower() # downcase\n",
    "    tokens = nltk.tokenize.word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# this function is run on each review ie. each row of input data!\n",
    "# understood!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to do some NLTK Downloader stuff - eg to download package 'punkt', etc. - see vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_index_map): 11088\n"
     ]
    }
   ],
   "source": [
    "# create a word-to-index map so that we can create our word-frequency vectors later\n",
    "# let's also save the tokenized versions so we don't have to tokenize again later\n",
    "\n",
    "word_index_map = {}   # this is going to be our dictionary of words\n",
    "current_index = 0\n",
    "positive_tokenized = []\n",
    "negative_tokenized = []\n",
    "orig_reviews = []\n",
    "\n",
    "for review in positive_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    positive_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "for review in negative_reviews:\n",
    "    orig_reviews.append(review.text)\n",
    "    tokens = my_tokenizer(review.text)\n",
    "    negative_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_index_map:\n",
    "            word_index_map[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "print(\"len(word_index_map):\", len(word_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create our input matrices\n",
    "def tokens_to_vector(tokens, label):\n",
    "    x = np.zeros(len(word_index_map) + 1) # last element is for the label\n",
    "    for t in tokens:\n",
    "        i = word_index_map[t]\n",
    "        x[i] += 1   # this will count the number of times each word occurs in a review\n",
    "    x = x / x.sum() # normalize it before setting label - wow!\n",
    "    x[-1] = label\n",
    "    return x\n",
    "\n",
    "N = len(positive_tokenized) + len(negative_tokenized)\n",
    "# (N x D+1 matrix - keeping them together for now so we can shuffle more easily later\n",
    "data = np.zeros((N, len(word_index_map) + 1))\n",
    "i = 0\n",
    "for tokens in positive_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 1)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "for tokens in negative_tokenized:\n",
    "    xy = tokens_to_vector(tokens, 0)\n",
    "    data[i,:] = xy\n",
    "    i += 1\n",
    "\n",
    "# shuffle the data and create train/test splits\n",
    "# try it multiple times!\n",
    "orig_reviews, data = shuffle(orig_reviews, data)\n",
    "\n",
    "X = data[:,:-1]\n",
    "Y = data[:,-1]\n",
    "\n",
    "# last 100 rows will be test\n",
    "Xtrain = X[:-100,]\n",
    "Ytrain = Y[:-100,]\n",
    "Xtest = X[-100:,]\n",
    "Ytest = Y[-100:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.78\n",
      "Test accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Train accuracy:\", model.score(Xtrain, Ytrain))\n",
    "print(\"Test accuracy:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this -0.5141826055964163\n",
      "unit -0.5706081101850577\n",
      "bad -0.7809020192680074\n",
      "cable 0.5922052124329176\n",
      "time -0.6872731977248827\n",
      "'ve 0.72704894193588\n",
      "month -0.6766952647611707\n",
      "sound 1.0017493590112683\n",
      "lot 0.672642185158915\n",
      "you 0.9652387417989492\n",
      "n't -2.107571337618963\n",
      "easy 1.7864763574259088\n",
      "quality 1.5596559000472965\n",
      "item -0.9793197060272332\n",
      "wa -1.428119521323052\n",
      "perfect 0.9879224185365869\n",
      "fast 0.9308922263928323\n",
      "ha 0.7756583059458371\n",
      "price 2.732570418712612\n",
      "value 0.5255676482748135\n",
      "money -1.0772755735946213\n",
      "memory 0.9883695849246882\n",
      "picture 0.5912660695747933\n",
      "buy -0.9128411721408817\n",
      "... -0.5460292461475468\n",
      "bit 0.5966772485093745\n",
      "happy 0.6209093486244378\n",
      "pretty 0.7593918358235872\n",
      "doe -1.1906036718066444\n",
      "highly 1.0123041013780265\n",
      "recommend 0.6073839734562343\n",
      "fit 0.5194929603276818\n",
      "customer -0.6259219727325055\n",
      "support -0.8459693637458909\n",
      "little 0.9451820153087533\n",
      "returned -0.7761527342056886\n",
      "excellent 1.2793398815241561\n",
      "love 1.1216158389338626\n",
      "feature 0.522877378093966\n",
      "software -0.5062667735053556\n",
      "home 0.5313958642079167\n",
      "week -0.7494270894965809\n",
      "using 0.678218967002166\n",
      "laptop 0.5989251860272624\n",
      "video 0.5050395494134334\n",
      "poor -0.7832263445374876\n",
      "look 0.5237851567962576\n",
      "then -1.1006147365568033\n",
      "tried -0.7387272292111067\n",
      "try -0.6569823979847224\n",
      "space 0.5575202022712756\n",
      "comfortable 0.6323294171095512\n",
      "hour -0.5762173370151524\n",
      "speaker 0.8313426410311126\n",
      "warranty -0.5428771213202178\n",
      "stopped -0.5319468047551693\n",
      "junk -0.5642733352298167\n",
      "returning -0.5339628296827583\n",
      "paper 0.6324464400300022\n",
      "return -1.1879485363713387\n",
      "waste -1.0094032852252495\n",
      "refund -0.6288049499091717\n",
      "Most wrong positive review (prob = 0.3380789798789407, pred = 0.0):\n",
      "\n",
      "A device like this either works or it doesn't.  This one happens to work\n",
      "\n",
      "Most wrong negative review (prob = 0.6062176516638647, pred = 1.0):\n",
      "\n",
      "The Voice recorder meets all my expectations and more\n",
      "Easy to use, easy to transfer great results\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's look at the weights for each word\n",
    "# try it with different threshold values!\n",
    "threshold = 0.5\n",
    "# for word, index in iteritems(word_index_map):   # LazyP made mistake on this line !\n",
    "for word, index in word_index_map.items():        # This is my corrected version !\n",
    "    weight = model.coef_[0][index]\n",
    "    if weight > threshold or weight < -threshold:\n",
    "        print(word, weight)\n",
    "\n",
    "\n",
    "# check misclassified examples\n",
    "preds = model.predict(X)\n",
    "P = model.predict_proba(X)[:,1] # p(y = 1 | x)\n",
    "\n",
    "# since there are many, just print the \"most\" wrong samples\n",
    "minP_whenYis1 = 1\n",
    "maxP_whenYis0 = 0\n",
    "wrong_positive_review = None\n",
    "wrong_negative_review = None\n",
    "wrong_positive_prediction = None\n",
    "wrong_negative_prediction = None\n",
    "for i in range(N):\n",
    "    p = P[i]\n",
    "    y = Y[i]\n",
    "    if y == 1 and p < 0.5:\n",
    "        if p < minP_whenYis1:\n",
    "            wrong_positive_review = orig_reviews[i]\n",
    "            wrong_positive_prediction = preds[i]\n",
    "            minP_whenYis1 = p\n",
    "    elif y == 0 and p > 0.5:\n",
    "        if p > maxP_whenYis0:\n",
    "            wrong_negative_review = orig_reviews[i]\n",
    "            wrong_negative_prediction = preds[i]\n",
    "            maxP_whenYis0 = p\n",
    "\n",
    "print(\"Most wrong positive review (prob = %s, pred = %s):\" % (minP_whenYis1, wrong_positive_prediction))\n",
    "print(wrong_positive_review)\n",
    "print(\"Most wrong negative review (prob = %s, pred = %s):\" % (maxP_whenYis0, wrong_negative_prediction))\n",
    "print(wrong_negative_review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just playing --- printing out the first 3 positive reviews\n",
    "# basically trung out the .text attribute --- worked !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I purchased this unit due to frequent blackouts in my area and 2 power supplies going bad.  It will run my cable modem, router, PC, and LCD monitor for 5 minutes.  This is more than enough time to save work and shut down.   Equally important, I know that my electronics are receiving clean power.\n",
      "\n",
      "I feel that this investment is minor compared to the loss of valuable data or the failure of equipment due to a power spike or an irregular power supply.\n",
      "\n",
      "As always, Amazon had it to me in <2 business days\n",
      "**************************************************\n",
      "\n",
      "I ordered 3 APC Back-UPS ES 500s on the recommendation of an employee of mine who used to work at APC. I've had them for about a month now without any problems. They've functioned properly through a few unexpected power interruptions. I'll gladly order more if the need arises.\n",
      "\n",
      "Pros:\n",
      " - Large plug spacing, good for power adapters\n",
      " - Simple design\n",
      " - Long cord\n",
      "\n",
      "Cons:\n",
      " - No line conditioning (usually an expensive option\n",
      "**************************************************\n",
      "\n",
      "Wish the unit had a separate online/offline light.  When power to the unit is missing, the single red light turns off only when the warning sounds.  The warning sound is like a lot of sounds you hear in the house so it isn't always easy to tell what is happening\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in positive_reviews:\n",
    "    print(positive_reviews[c].text + '*'*50)\n",
    "    c += 1\n",
    "    if c > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
